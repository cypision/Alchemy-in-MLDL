{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title:  \"What is Stacking\"\n",
    "excerpt: \"Stacking , Ensemble\"\n",
    "\n",
    "categories:\n",
    "  - Machine-Learning\n",
    "tags:\n",
    "  - Stacking\n",
    "  - Ensemble\n",
    "  - Medium\n",
    "last_modified_at: 2020-05-09T21:15:00-05:00\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference  \n",
    "- 이수진의 머신러닝 스태킹 앙상블 (https://lsjsj92.tistory.com/559?category=853217)\n",
    "- 이수진의 머신러닝 스태킹 앙상블 베이식 (https://lsjsj92.tistory.com/558?category=853217)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking-Ensemble Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 개별학습기의 결과물을 train 셋으로 하는 메타 학습기를 만들고, 이를 훈련시켜서 예측하는 방법. 앙상블의 일종이다.\n",
    "- stacked generalization 의 줄임말이다.  \n",
    "- 따라서, 두 가지 컨셉의 분류기가 필요하다.\n",
    " > 개별 분류기 각각의 분류기  \n",
    " > 개별 분류기의 예측값을 학습셋으로 활용하는 메타 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set() # setting seaborn default for plots\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Classifier Modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer,load_iris\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.data\n",
    "y = data.target\n",
    "x_train,x_test,y_train,y_test = model_selection.train_test_split(x,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (30, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.6, 3.6, 1. , 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [4.8, 3.4, 1.6, 0.2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (30, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "print(x_train_scaled.shape,x_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9249710144927537\n"
     ]
    }
   ],
   "source": [
    "clf01 = RandomForestClassifier(n_estimators=13)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf01, x_train_scaled, y_train, cv=5, n_jobs=1, scoring=scoring)\n",
    "print(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96       1.         0.83333333 1.         0.91304348]\n"
     ]
    }
   ],
   "source": [
    "clf02 = GaussianNB()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf02, x_train_scaled, y_train, cv=5, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.13"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9329420289855073\n"
     ]
    }
   ],
   "source": [
    "clf03 = SVC(gamma='auto')\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf03, x_train_scaled, y_train, cv=5, n_jobs=1, scoring=scoring)\n",
    "print(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 최종모델 Meta clf\n",
    "from lightgbm import LGBMClassifier,plot_importance\n",
    "meta_clf = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf01.fit(x_train_scaled, y_train)\n",
    "clf02.fit(x_train_scaled, y_train)\n",
    "clf03.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf01_pred = clf01.predict(x_test_scaled)\n",
    "clf02_pred = clf02.predict(x_test_scaled)\n",
    "clf03_pred = clf03.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "## 현 상태 그대로의 y_test 결과\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cla01_y_test_rslt = accuracy_score(y_test, clf01_pred, normalize=True, sample_weight=None)\n",
    "cla02_y_test_rslt = accuracy_score(y_test, clf02_pred, normalize=True, sample_weight=None)\n",
    "cla03_y_test_rslt = accuracy_score(y_test, clf03_pred, normalize=True, sample_weight=None)\n",
    "print(cla01_y_test_rslt,cla02_y_test_rslt,cla03_y_test_rslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 30)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.array([clf01_pred,clf02_pred,clf03_pred])\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.transpose(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "meta_clf.fit(new_data,y_test)\n",
    "meta_predict = meta_clf.predict(new_data)\n",
    "meta_y_test_rslt = accuracy_score(y_test, meta_predict, normalize=True, sample_weight=None)\n",
    "print(np.mean(meta_y_test_rslt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과는 상당히 구리지만....넘어가는 걸로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참조 Blog 원본데로, breast_canser 데이터로 실습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "x_data = data.data\n",
    "y_data = data.target\n",
    "X_train,X_test,y_train,y_test = model_selection.train_test_split(x_data,y_data,test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma= 'auto')\n",
    "rf = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train,y_train)\n",
    "rf.fit(X_train,y_train)\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = svm.predict(X_test)\n",
    "rf_pred = rf.predict(X_test)\n",
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 114)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.array([svm_pred,rf_pred,lr_pred])\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.transpose(new_data)\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(new_data,y_test)\n",
    "lgbm_pred = lgbm.predict(new_data)\n",
    "meta_y_test_rslt = accuracy_score(y_test, lgbm_pred, normalize=True, sample_weight=None)\n",
    "print(np.mean(meta_y_test_rslt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking-Ensemble K-Fold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
