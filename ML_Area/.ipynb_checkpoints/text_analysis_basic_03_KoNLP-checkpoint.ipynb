{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title:  \"혼자하는 Text분석_03\"\n",
    "excerpt: \"Sckit-lean library 과 Keras를 사용한 Text 분석 비교\"\n",
    "\n",
    "categories:\n",
    "  - Machine-Learning\n",
    "tags:\n",
    "  - KoNLPy\n",
    "  - text anlysis\n",
    "  - 머신러닝\n",
    "  - linux docker\n",
    "last_modified_at: 2020-03-21T16:13:00-05:00\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이 분석은 개인적인 local 사정상, Docker 환경에서 실습했음을 알린다.  \n",
    "### Docker 환경을 만든 이유는 local OS : Window 10 Home edition 이기 때문이다.  \n",
    " - docker toolbox 로 진행했는데, 꽤나 힘들었다.\n",
    "KoNLPy 순서로 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 외에도, KoNLPy (형태소 분석기 = 한국어 전용 어간분석기) 를 사용할 수 있고, 실제로도 이를 많이 사용한다.  \n",
    "그러나, 현재 실습 환경이 Window 인 관계로, 생략한다. 이는 추후 Collab 에서 활용하도록 한다  \n",
    "\"KoNLPy의 Mecab() 클래스는 윈도우에서 지원되지 않습니다.\" (http://konlpy.org/ko/latest/install/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 라이브러리 로드\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# 시각화 결과가 선명하게 표시되도록\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화를 위한 한글폰트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window 한글폰트 설정\n",
    "# plt.rc(\"font\", family=\"Malgun Gothic\")\n",
    "# Mac 한글폰트 설정\n",
    "plt.rc(\"font\", family=\"AppleGothic\")\n",
    "plt.rc('axes', unicode_minus=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naver Movie Review 가져오기  \n",
    "[이미 github 에 txt 파일로 정제된것을 활용했다.](https://github.com/e9t/nsmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                           document  label\n",
       "0  9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1  3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('/home/cypision/Alchemy/dataset/naver_movie_sample/ratings_train.txt',delimiter='\\t',keep_default_na=False)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lable 이 0 이면 부정적인 리뷰. 1이면 긍정적인 리뷰다  \n",
    "numpy 배열로 바꿔보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = df_train.document.values\n",
    "y_train = df_train.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000,) (150000,)\n"
     ]
    }
   ],
   "source": [
    "print(text_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> 1\n"
     ]
    }
   ],
   "source": [
    "print(type(text_train),text_train.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## text data 불러와서 가공하기\n",
    "df_test = pd.read_csv('/home/cypision/Alchemy/dataset/naver_movie_sample/ratings_test.txt',delimiter='\\t',keep_default_na=False)\n",
    "text_test = df_test['document'].values\n",
    "y_test = df_test.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 탐색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, array([75173, 74827]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_train), np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, array([24827, 25173]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_test), np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KoNLPy 를 tokenizer 로 활용하기  \n",
    "KoNLPy 는 앞선 post 에서 언급했던, 형태소 분석기이고 기본적으로 5개 정도가 있다.  \n",
    "여기서는 2개 정도만 실습해보기로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Okt 이른바 Twitter 형태소 분석기 활용__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt ## Twitter --> Okt 로 버전업하면서 명칭이 바뀌었다.\n",
    "twitter_tag = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_tokenizer(text):\n",
    "    return twitter_tag.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_param_grid = {'tfidfvectorizer__min_df':[3,5,7],\n",
    "                  'tfidfvectorizer__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "                  'logisticregression__C':[0.1,1,10]}\n",
    "## 여기가 핵심이다.\n",
    "## 기본 TfidfVectorizer() 는 정규식을 활용하자만, 여기서는 KoNLPy 에 해당하는 어간(형태소) tokenizer 를 사용한다.\n",
    "t_pipe = make_pipeline(TfidfVectorizer(tokenizer=twitter_tokenizer),LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grid = GridSearchCV(t_pipe,twit_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grid.fit(text_train[0:1000],y_train[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718\n",
      "{'logisticregression__C': 1, 'tfidfvectorizer__min_df': 3, 'tfidfvectorizer__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "print(t_grid.best_score_)\n",
    "print(t_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 최적의 조합을 찾았으니, text set를 변환시키고 (KoNLPy tokenzier 를 사용하고) 실제 test 결과를 구해본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=3, ngram_range=(1, 3), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token...\n",
       "                                 tokenizer=<function twitter_tokenizer at 0x7f0b5545f268>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_konlypy = t_grid.best_estimator_.named_steps['tfidfvectorizer'].transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = t_grid.best_estimator_.named_steps['logisticregression'].score(x_test_konlypy,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70698\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딱히 비교할 건 없지만, 꽤나 잘 맞는다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Mecab 형태소 분석기 활용__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_tokenizer(text):\n",
    "    return mecab.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_param_grid = {'tfidfvectorizer__min_df':[3,5,7],\n",
    "                  'tfidfvectorizer__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "                  'logisticregression__C':[0.1,1,10]}\n",
    "## 여기가 핵심이다.\n",
    "## 기본 TfidfVectorizer() 는 정규식을 활용하자만, 여기서는 KoNLPy 에 해당하는 어간(형태소) tokenizer 를 사용한다.\n",
    "m_pipe = make_pipeline(TfidfVectorizer(tokenizer=mecab_tokenizer),LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_grid = GridSearchCV(m_pipe,mecab_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=N...\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'logisticregression__C': [0.1, 1, 10],\n",
       "                         'tfidfvectorizer__min_df': [3, 5, 7],\n",
       "                         'tfidfvectorizer__ngram_range': [(1, 1), (1, 2),\n",
       "                                                          (1, 3)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_grid.fit(text_train[0:1000],y_train[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7529999999999999\n",
      "{'logisticregression__C': 1, 'tfidfvectorizer__min_df': 3, 'tfidfvectorizer__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(m_grid.best_score_)\n",
    "print(m_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=3, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token...\n",
       "                                 tokenizer=<function mecab_tokenizer at 0x7f0b2f7a3378>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_konlypy = m_grid.best_estimator_.named_steps['tfidfvectorizer'].transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = m_grid.best_estimator_.named_steps['logisticregression'].score(x_test_konlypy,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74632\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다...이렇다 할 특별한 부분은 없지만...결과는 훨씬 좋은 듯. ㅋㅋ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
