{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title:  \"혼자하는 Text분석_05\"\n",
    "excerpt: \"Keras에서 Embedding 이후, RNN적용한 Text 분석 비교\"\n",
    "\n",
    "categories:\n",
    "  - Machine-Learning\n",
    "tags:\n",
    "  - Keras\n",
    "  - text anlysis\n",
    "  - 머신러닝\n",
    "  - keras tokenizer\n",
    "  - minsuk-heo youtube  \n",
    "last_modified_at: 2020-03-27T16:13:00-05:00\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 posting 내용은 필자가 존경하는 minsuk-heo 님의 youtube 강의노트를 사용해서, Embedding 에 대한 나름의 정리를 하고자 한다.  \n",
    "(https://github.com/minsuk-heo/python_tutorial/blob/master/data_science/nlp/word2vec_tensorflow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "here I implement word2vec with very simple example using tensorflow  \n",
    "word2vec is vector representation for words with similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "we will use only 10 sentences to create word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['king is a strong man', \n",
    "          'queen is a wise woman', \n",
    "          'boy is a young man',\n",
    "          'girl is a young woman',\n",
    "          'prince is a young king',\n",
    "          'princess is a young queen',\n",
    "          'man is strong', \n",
    "          'woman is pretty',\n",
    "          'prince is a boy will be king',\n",
    "          'princess is a girl will be queen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쓸데없는 단어 제거...관용사 a 같은거.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(corpus):\n",
    "    stop_words = ['is', 'a', 'will', 'be']\n",
    "    results = []\n",
    "    for text in corpus:\n",
    "        tmp = text.split(' ')\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in tmp:\n",
    "                tmp.remove(stop_word)\n",
    "        results.append(\" \".join(tmp))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = remove_stop_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## corpus 를 이후 unique 하게 정리해서, corpus 의 어휘사전을 만들면,\n",
    "words = []\n",
    "for text in corpus:\n",
    "    for word in text.split(' '):\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boy',\n",
       " 'girl',\n",
       " 'king',\n",
       " 'man',\n",
       " 'pretty',\n",
       " 'prince',\n",
       " 'princess',\n",
       " 'queen',\n",
       " 'strong',\n",
       " 'wise',\n",
       " 'woman',\n",
       " 'young'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generation\n",
    "we will generate label for each word using skip gram. - wor2Vec 의 알고리즘 중 하나  \n",
    "※ wor2vec : Embedding 기법의 한 종류이고, target 을 인접한 neighbor 단어들로 잡는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "## 단어 사전 만들기, 단어에 정수 sequence 를 부여한다.\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for sentence in corpus: ## data의 1개의 smaple 씩, 그니깐, 1개의 문장씩 sentences 란 새로운 list 에 단어별로 list를 만든다.\n",
    "    sentences.append(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 문장 value:['king', 'strong', 'man'] 그리고 총 length:3\n",
      "2번째 문장 value:['queen', 'wise', 'woman'] 그리고 총 length:3\n",
      "3번째 문장 value:['boy', 'young', 'man'] 그리고 총 length:3\n",
      "4번째 문장 value:['girl', 'young', 'woman'] 그리고 총 length:3\n",
      "5번째 문장 value:['prince', 'young', 'king'] 그리고 총 length:3\n",
      "6번째 문장 value:['princess', 'young', 'queen'] 그리고 총 length:3\n",
      "7번째 문장 value:['man', 'strong'] 그리고 총 length:2\n",
      "8번째 문장 value:['woman', 'pretty'] 그리고 총 length:2\n",
      "9번째 문장 value:['prince', 'boy', 'king'] 그리고 총 length:3\n",
      "10번째 문장 value:['princess', 'girl', 'queen'] 그리고 총 length:3\n"
     ]
    }
   ],
   "source": [
    "cnt = 0 \n",
    "for sentence in sentences:\n",
    "    cnt +=1\n",
    "    print(\"{}번째 문장 value:{} 그리고 총 length:{}\".format(cnt,sentence,len(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과처럼, 각 문장별로 길이가 다르다...keras 로 치면, max_len 에 해당하는 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 2\n",
    "data = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence): # 개별 sample(문장별) \n",
    "         #각 해당단어에서, 2개 씩 좌우로 후보 단어더미를 list 로 만들고 차례대로 neighbor 로 추출\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] :\n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor]) # 해당단어만 빼고, 이웃되는 (좌 0~2개,우 0~2개 총 4개이하) 로 꾸러미를 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king strong man\n",
      "queen wise woman\n",
      "boy young man\n",
      "girl young woman\n",
      "prince young king\n",
      "princess young queen\n",
      "man strong\n",
      "woman pretty\n",
      "prince boy king\n",
      "princess girl queen\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for text in corpus:\n",
    "    print(text)\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['input', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>king</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>king</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strong</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strong</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>queen</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>queen</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wise</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wise</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>woman</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>woman</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>boy</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input   label\n",
       "0     king  strong\n",
       "1     king     man\n",
       "2   strong    king\n",
       "3   strong     man\n",
       "4      man    king\n",
       "5      man  strong\n",
       "6    queen    wise\n",
       "7    queen   woman\n",
       "8     wise   queen\n",
       "9     wise   woman\n",
       "10   woman   queen\n",
       "11   woman    wise\n",
       "12     boy   young"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(13) ## input 과 타겟 label 등장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'wise': 0,\n",
       " 'strong': 1,\n",
       " 'young': 2,\n",
       " 'queen': 3,\n",
       " 'king': 4,\n",
       " 'boy': 5,\n",
       " 'girl': 6,\n",
       " 'woman': 7,\n",
       " 'prince': 8,\n",
       " 'man': 9,\n",
       " 'princess': 10,\n",
       " 'pretty': 11}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "word2int # 어휘사전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "# function to convert numbers to one hot vectors\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM) ## 여기서는 max_len 이 결국 len(words) = 12 인 것을 알 수 있다. \n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "X = [] # input word\n",
    "Y = [] # target word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wise', 'strong', 'young', 'queen', 'king', 'boy', 'girl', 'woman', 'prince', 'man', 'princess', 'pretty'} \t 12\n"
     ]
    }
   ],
   "source": [
    "print(words, \"\\t\", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
    "    Y.append(to_one_hot_encoding(word2int[ y ]))\n",
    "## X:input 데이터는 sequence_length (통상 keras 모델 내부에서는 max_len 으로 configure 하는) 값이 12로 설정된것을 알 수 있다.\n",
    "\n",
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 12)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making placeholders for X_train and Y_train\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "# word embedding will be 2 dimension for 2d visualization\n",
    "EMBEDDING_DIM = 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tensorflow 로 표현되었지만 여기서부터가 Embedding layer 구성 부분이다. Start**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONE_HOT_DIM: 12 / EMBEDDING_DIM: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"ONE_HOT_DIM:\",ONE_HOT_DIM,\"/ EMBEDDING_DIM:\",EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer: which represents word vector eventually\n",
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([1])) #bias\n",
    "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
    "## keras 와 헷갈렸던 것은 keras 의 max_len 개념이다. keras 에서는 Embedding 층을 만들때, max_len 보다 훨씬 큰 값으로 공간을 구성하고, 실제로 작업도 한다.\n",
    "## 여기서는 ONE_HOT_DIM 이 그런 역할을 하는데, 실제로, one-hot-encoding 으로 사전에 없는 단어는 모두 0으로 해서 들어오면서 shape을 맞추고 들어온다. \n",
    "\n",
    "# output layer ## target 을 값을 설정하는 것\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
    "\n",
    "# loss function: cross entropy\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
    "\n",
    "# training operation\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tensorflow 로 표현되었지만 여기서부터가 Embedding layer 구성 부분이다. End**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 loss is :  5.0788465\n",
      "iteration 3000 loss is :  1.8832028\n",
      "iteration 6000 loss is :  1.7283807\n",
      "iteration 9000 loss is :  1.6977545\n",
      "iteration 12000 loss is :  1.6829585\n",
      "iteration 15000 loss is :  1.6734779\n",
      "iteration 18000 loss is :  1.6665666\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "iteration = 20000\n",
    "for i in range(iteration):\n",
    "    # input is X_train which is one hot encoded word\n",
    "    # label is Y_train which is one hot encoded neighbor word\n",
    "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
    "    if i % 3000 == 0:\n",
    "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.4922278  -3.5493858 ]\n",
      " [ 2.8152335   1.5877781 ]\n",
      " [ 0.36534062 -0.11101   ]\n",
      " [-0.5324085  -0.5098076 ]\n",
      " [-0.1849049   1.0182045 ]\n",
      " [-0.04679373  1.0136434 ]\n",
      " [-0.75224614 -0.77613664]\n",
      " [-1.8010311  -1.0071619 ]\n",
      " [-1.0527248   5.2118983 ]\n",
      " [-1.2981308   5.186151  ]\n",
      " [-4.9132915  -3.2144003 ]\n",
      " [ 2.0580463  -2.0683904 ]]\n"
     ]
    }
   ],
   "source": [
    "# Now the hidden layer (W1 + b1) is actually the word look up table\n",
    "vectors = sess.run(W1 + b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wise</td>\n",
       "      <td>-2.492228</td>\n",
       "      <td>-3.549386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strong</td>\n",
       "      <td>2.815233</td>\n",
       "      <td>1.587778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>young</td>\n",
       "      <td>0.365341</td>\n",
       "      <td>-0.111010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>queen</td>\n",
       "      <td>-0.532408</td>\n",
       "      <td>-0.509808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>king</td>\n",
       "      <td>-0.184905</td>\n",
       "      <td>1.018204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boy</td>\n",
       "      <td>-0.046794</td>\n",
       "      <td>1.013643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>girl</td>\n",
       "      <td>-0.752246</td>\n",
       "      <td>-0.776137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>woman</td>\n",
       "      <td>-1.801031</td>\n",
       "      <td>-1.007162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prince</td>\n",
       "      <td>-1.052725</td>\n",
       "      <td>5.211898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>man</td>\n",
       "      <td>-1.298131</td>\n",
       "      <td>5.186151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>princess</td>\n",
       "      <td>-4.913291</td>\n",
       "      <td>-3.214400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pretty</td>\n",
       "      <td>2.058046</td>\n",
       "      <td>-2.068390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word        x1        x2\n",
       "0       wise -2.492228 -3.549386\n",
       "1     strong  2.815233  1.587778\n",
       "2      young  0.365341 -0.111010\n",
       "3      queen -0.532408 -0.509808\n",
       "4       king -0.184905  1.018204\n",
       "5        boy -0.046794  1.013643\n",
       "6       girl -0.752246 -0.776137\n",
       "7      woman -1.801031 -1.007162\n",
       "8     prince -1.052725  5.211898\n",
       "9        man -1.298131  5.186151\n",
       "10  princess -4.913291 -3.214400\n",
       "11    pretty  2.058046 -2.068390"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word vector in 2d chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "    ax.annotate(word, (x1,x2 ))\n",
    "    \n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    " \n",
    "plt.xlim(x_axis_min,x_axis_max)\n",
    "plt.ylim(y_axis_min,y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
