{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title:  \"Neuralnet Basic 06\"\n",
    "excerpt: \"Basic Neural Net using numpy,tensor-flow,keras\"\n",
    "\n",
    "categories:\n",
    "  - Deep-Learning\n",
    "tags:\n",
    "  - DL\n",
    "  - Neuralnet Using keras\n",
    "  - KEARS 창시자에게 배우는 딥러닝\n",
    "  - 딥러닝\n",
    "last_modified_at: 2020-03-06T18:06:00-05:00\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEARS 창시자에게 배우는 딥러닝 - 3장 -01 이진분류문제\n",
    "> Basic 03 에서, 사용한, 간단한 영화리뷰에 대해서 좀더 Neural Net 의 일반화 기법을 알아본다.  \n",
    "> 핵심은 과적합(overfitting) 피하기 이다.\n",
    "> [책 관련 Blog 로 이동](https://tensorflow.blog/%EC%BC%80%EB%9D%BC%EC%8A%A4-%EC%B0%BD%EC%8B%9C%EC%9E%90%EC%97%90%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend import tensorflow_backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "## num_words=10000 는 훈련데이터에서, 자주 사용하는 단어 1만개만 사용하겠다는 의미임\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------------**데이터 내용 파악 start**--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape (25000,)\n",
      "train_labels.shape (25000,)\n",
      "test_data.shape (25000,)\n",
      "test_labels (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data.shape\",train_data.shape)\n",
    "print(\"train_labels.shape\",train_labels.shape)\n",
    "print(\"test_data.shape\",test_data.shape)\n",
    "print(\"test_labels\",test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__언뜻 보기엔 2D tensor 같지만, np.array로 1개의 벡터 안에, 원소가 list 형태임. 이대로는 keras 모델에 집어넣을 수 없음__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(train_data.ndim) ## 1D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d5031e034ebb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "train_data[12].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 13, 119, 954, 189, 1554, 13, 92, 459, 48]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_data[12]))\n",
    "print(type(train_data[12]))\n",
    "train_data[12][0:10] ## 25번째 데이터의 구성을 보면, 총 142개의 단어로 되어 있고, 0~9번째까지의 단어는 하기와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 14, 9, 6, 55, 641, 2854, 212, 44, 6]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_data[25]))\n",
    "train_data[25][0:10] ## 25번째 데이터의 구성을 보면, 총 142개의 단어로 되어 있고, 0~9번째까지의 단어는 하기와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data]) ## num_words=10000 제한이 없었으면, 88586 단어의 데이터가 존재한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "124\n",
      "118\n",
      "281\n",
      "252\n"
     ]
    }
   ],
   "source": [
    "for line_idx in range(0,len(train_data)):\n",
    "    if (line_idx%5000)==0:\n",
    "        print(len(train_data[line_idx]))\n",
    "## 보시다시피, 각 train_data 라인당 모두 길이가 다르다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------------**데이터 내용 파악 end**--------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망에는 list를 input data로 활용할수없기때문에, vector 로 바꾼다. \n",
    "이때, Embedding 이나, one-hotencoding을 사용하는데, 여기서는 one-hotencoding을 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape (25000,)\n",
      "test_data.shape (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data.shape\",train_data.shape)\n",
    "print(\"test_data.shape\",test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 언급했듯이, 현재는 1D tensor 이기에, 이대로는 넣을 수 없다. 따라서, 2D tensor , ndim=2, np.array type 으로 바꿔줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터를 벡터로 변환합니다\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터를 벡터로 변환합니다\n",
    "x_test = vectorize_sequences(test_data)\n",
    "# 레이블을 벡터로 변환합니다\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__과적합 피하기__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__원본 네트워크__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "original_model.add(layers.Dense(16, activation='relu'))\n",
    "original_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "original_model.compile(optimizer='rmsprop',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__node 를 줄인 작은 네트워크 모델__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_model = models.Sequential()\n",
    "smaller_model.add(layers.Dense(6, activation='relu', input_shape=(10000,)))\n",
    "smaller_model.add(layers.Dense(6, activation='relu'))\n",
    "smaller_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "smaller_model.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 5s 180us/step - loss: 0.4440 - acc: 0.8251 - val_loss: 0.3286 - val_acc: 0.8835\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 3s 140us/step - loss: 0.2573 - acc: 0.9078 - val_loss: 0.2864 - val_acc: 0.8882\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 4s 144us/step - loss: 0.1991 - acc: 0.9292 - val_loss: 0.2821 - val_acc: 0.8891\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 4s 143us/step - loss: 0.1666 - acc: 0.9412 - val_loss: 0.2939 - val_acc: 0.8844\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 4s 144us/step - loss: 0.1435 - acc: 0.9501 - val_loss: 0.3116 - val_acc: 0.8804\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 4s 151us/step - loss: 0.1257 - acc: 0.9558 - val_loss: 0.3483 - val_acc: 0.8721\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 4s 145us/step - loss: 0.1104 - acc: 0.9615 - val_loss: 0.3598 - val_acc: 0.8722\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 4s 148us/step - loss: 0.0977 - acc: 0.9669 - val_loss: 0.3975 - val_acc: 0.8662\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.0841 - acc: 0.9721 - val_loss: 0.4339 - val_acc: 0.8611\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.0755 - acc: 0.9757 - val_loss: 0.4997 - val_acc: 0.8524\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.0684 - acc: 0.9778 - val_loss: 0.4871 - val_acc: 0.8587\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.0563 - acc: 0.9831 - val_loss: 0.5220 - val_acc: 0.8557\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 3s 139us/step - loss: 0.0513 - acc: 0.9843 - val_loss: 0.5351 - val_acc: 0.8579\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 3s 139us/step - loss: 0.0423 - acc: 0.9881 - val_loss: 0.6093 - val_acc: 0.8501\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 4s 141us/step - loss: 0.0363 - acc: 0.9894 - val_loss: 0.6115 - val_acc: 0.8558\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 4s 143us/step - loss: 0.0310 - acc: 0.9909 - val_loss: 0.6426 - val_acc: 0.8536\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.0265 - acc: 0.9926 - val_loss: 0.7693 - val_acc: 0.8417\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 4s 140us/step - loss: 0.0208 - acc: 0.9946 - val_loss: 0.7221 - val_acc: 0.8516\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 4s 141us/step - loss: 0.0198 - acc: 0.9949 - val_loss: 0.7739 - val_acc: 0.8476\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 4s 146us/step - loss: 0.0151 - acc: 0.9965 - val_loss: 0.9723 - val_acc: 0.8298\n"
     ]
    }
   ],
   "source": [
    "original_hist = original_model.fit(x_train, y_train,\n",
    "                                   epochs=20,\n",
    "                                   batch_size=512,\n",
    "                                   validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 4s 153us/step - loss: 0.5670 - acc: 0.7410 - val_loss: 0.4849 - val_acc: 0.8256\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 4s 149us/step - loss: 0.3924 - acc: 0.8895 - val_loss: 0.3609 - val_acc: 0.8780\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 4s 144us/step - loss: 0.2791 - acc: 0.9174 - val_loss: 0.3012 - val_acc: 0.8879\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 4s 146us/step - loss: 0.2213 - acc: 0.9278 - val_loss: 0.2823 - val_acc: 0.8900\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 4s 150us/step - loss: 0.1877 - acc: 0.9375 - val_loss: 0.2816 - val_acc: 0.8863\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 4s 151us/step - loss: 0.1649 - acc: 0.9448 - val_loss: 0.2858 - val_acc: 0.8856\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 4s 144us/step - loss: 0.1467 - acc: 0.9518 - val_loss: 0.2954 - val_acc: 0.8817\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 4s 145us/step - loss: 0.1330 - acc: 0.9558 - val_loss: 0.3067 - val_acc: 0.8796\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 4s 140us/step - loss: 0.1196 - acc: 0.9620 - val_loss: 0.3223 - val_acc: 0.8773\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 3s 140us/step - loss: 0.1095 - acc: 0.9648 - val_loss: 0.3358 - val_acc: 0.8752\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.0988 - acc: 0.9690 - val_loss: 0.3549 - val_acc: 0.8712\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 4s 144us/step - loss: 0.0898 - acc: 0.9728 - val_loss: 0.3790 - val_acc: 0.8692\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 4s 144us/step - loss: 0.0816 - acc: 0.9759 - val_loss: 0.3900 - val_acc: 0.8676\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 4s 144us/step - loss: 0.0743 - acc: 0.9772 - val_loss: 0.4130 - val_acc: 0.8654\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 4s 144us/step - loss: 0.0675 - acc: 0.9806 - val_loss: 0.4394 - val_acc: 0.8631\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 4s 144us/step - loss: 0.0605 - acc: 0.9828 - val_loss: 0.4665 - val_acc: 0.8602\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.0554 - acc: 0.9840 - val_loss: 0.4742 - val_acc: 0.8618\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.0500 - acc: 0.9867 - val_loss: 0.5050 - val_acc: 0.8592\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.0456 - acc: 0.9883 - val_loss: 0.5210 - val_acc: 0.8591\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.0409 - acc: 0.9896 - val_loss: 0.5714 - val_acc: 0.8536\n"
     ]
    }
   ],
   "source": [
    "smaller_model_hist = smaller_model.fit(x_train, y_train,\n",
    "                                       epochs=20,\n",
    "                                       batch_size=512,\n",
    "                                       validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 21)\n",
    "original_val_loss = original_hist.history['val_loss']\n",
    "smaller_model_val_loss = smaller_model_hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ‘b+’는 파란색 덧셈 기호을 의미합니다\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "# ‘bo’는 파란색 점을 의미합니다\n",
    "plt.plot(epochs, smaller_model_val_loss, 'bo', label='Smaller model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오리지널 보다, node 가 더 적게 학습된 모델이, validation loss 수렴이 좀 더 늦게 이루짐을 알 수 있다.  \n",
    "오리지널은 4에서부터, 다시금 loss 값이 증가하는데,  \n",
    "node가 적읍 변형모델은 epoch 6 정도에서부터, loss 가 증가하고, 그렇게 가파르지도 않다.  \n",
    "node 가 더 많을 수록, 좀 더 과적합되기 쉽다는 것을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__node 를 확 늘린 큰 네트워크 모델__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_model = models.Sequential()\n",
    "bigger_model.add(layers.Dense(1024, activation='relu', input_shape=(10000,)))\n",
    "bigger_model.add(layers.Dense(1024, activation='relu'))\n",
    "bigger_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "bigger_model.compile(optimizer='rmsprop',\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 5s 204us/step - loss: 0.5525 - acc: 0.7891 - val_loss: 0.2816 - val_acc: 0.8851\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 5s 184us/step - loss: 0.2181 - acc: 0.9138 - val_loss: 0.3308 - val_acc: 0.8698\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 5s 186us/step - loss: 0.1150 - acc: 0.9600 - val_loss: 0.3660 - val_acc: 0.8836\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 5s 183us/step - loss: 0.0939 - acc: 0.9806 - val_loss: 0.4565 - val_acc: 0.8849\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 5s 184us/step - loss: 0.1066 - acc: 0.9867 - val_loss: 0.4866 - val_acc: 0.8824\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 5s 189us/step - loss: 0.0726 - acc: 0.9870 - val_loss: 0.4781 - val_acc: 0.8803\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 5s 194us/step - loss: 5.9183e-04 - acc: 1.0000 - val_loss: 0.6355 - val_acc: 0.8826\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 5s 197us/step - loss: 5.3420e-05 - acc: 1.0000 - val_loss: 0.7792 - val_acc: 0.8821\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 5s 194us/step - loss: 4.8513e-06 - acc: 1.0000 - val_loss: 0.8524 - val_acc: 0.8813\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 5s 185us/step - loss: 7.0338e-07 - acc: 1.0000 - val_loss: 0.9299 - val_acc: 0.8817\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 5s 192us/step - loss: 1.8404e-07 - acc: 1.0000 - val_loss: 0.9912 - val_acc: 0.8821\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 5s 184us/step - loss: 1.2659e-07 - acc: 1.0000 - val_loss: 1.0203 - val_acc: 0.8821\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 5s 187us/step - loss: 1.1641e-07 - acc: 1.0000 - val_loss: 1.0368 - val_acc: 0.8820\n",
      "Epoch 14/20\n",
      "24576/25000 [============================>.] - ETA: 0s - loss: 1.1336e-07 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "bigger_model_hist = bigger_model.fit(x_train, y_train,\n",
    "                                     epochs=20,\n",
    "                                     batch_size=512,\n",
    "                                     validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_model_val_loss = bigger_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, bigger_model_val_loss, 'bo', label='Bigger model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_loss = original_hist.history['loss']\n",
    "bigger_model_train_loss = bigger_model_hist.history['loss']\n",
    "\n",
    "plt.plot(epochs, original_train_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, bigger_model_train_loss, 'bo', label='Bigger model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훨씬 더 많은 node 를(이른바 네트워크 용량을 증가시켰을때) 사용한 모델은 빠르게 loss 값이 감소하나, 더 쉽게 빨리 과대적합이 일어난다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[keras 개념설명 blog](https://tykimos.github.io/2017/01/27/Keras_Talk/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 keras 를 통해 볼것은 규제추가(정규화) 와 Drop out 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "l2_model = models.Sequential()\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu', input_shape=(10000,)))\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpt_model = models.Sequential()\n",
    "dpt_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "dpt_model.add(layers.Dropout(0.5))\n",
    "dpt_model.add(layers.Dense(16, activation='relu'))\n",
    "dpt_model.add(layers.Dropout(0.5))\n",
    "dpt_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "dpt_model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상세한 설명은 생략한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
