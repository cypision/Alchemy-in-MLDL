{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title:  \"20 News Group Basic\"  \n",
    "excerpt: \"Text Analysis\"  \n",
    "\n",
    "categories:  \n",
    "  - Deep-Learning  \n",
    "tags:  \n",
    "  - Text Analysis\n",
    "  - fetch_20newsgroups  \n",
    "  - csr-matrix\n",
    "  - CountVectorizer  \n",
    "  - TfidfVectorizer\n",
    "last_modified_at: 2020-08-09T14:13:00-05:00\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference  \n",
    "* 파이썬 머신러닝 완벽가이드 - 권철민\n",
    "* NCIA shkim.hi@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20-뉴스그룹 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로딩과 데이터 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news_data = fetch_20newsgroups(subset='all',random_state=156)\n",
    "## 기본제공해주는 파라미터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(news_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bunch type : scikit-learn 쪽에서 주로 사용하는 Bunch type. dict 와 유사한 객체이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(news_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(news_data.data), type(news_data.target_names), type(news_data.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.unique(news_data.target))\n",
    "print(news_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index (0) : topic alt.atheism \n",
      "index (1) : topic comp.graphics \n",
      "index (2) : topic comp.os.ms-windows.misc \n",
      "index (3) : topic comp.sys.ibm.pc.hardware \n",
      "index (4) : topic comp.sys.mac.hardware \n",
      "index (5) : topic comp.windows.x \n",
      "index (6) : topic misc.forsale \n",
      "index (7) : topic rec.autos \n",
      "index (8) : topic rec.motorcycles \n",
      "index (9) : topic rec.sport.baseball \n",
      "index (10) : topic rec.sport.hockey \n",
      "index (11) : topic sci.crypt \n",
      "index (12) : topic sci.electronics \n",
      "index (13) : topic sci.med \n",
      "index (14) : topic sci.space \n",
      "index (15) : topic soc.religion.christian \n",
      "index (16) : topic talk.politics.guns \n",
      "index (17) : topic talk.politics.mideast \n",
      "index (18) : topic talk.politics.misc \n",
      "index (19) : topic talk.religion.misc \n"
     ]
    }
   ],
   "source": [
    "for i,val in zip(np.unique(news_data.target),news_data.target_names):\n",
    "    print(\"index ({}) : topic {} \".format(i,val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846 1303 2944\n",
      "20\n",
      "(18846,)\n"
     ]
    }
   ],
   "source": [
    "print(len(news_data.data), len(news_data.data[0]),len(news_data.data[1]))\n",
    "print(len(news_data.target_names))\n",
    "print(news_data.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
      "Subject: Re: Observation re: helmets\n",
      "Organization: Sun Microsystems, RTP, NC\n",
      "Lines: 21\n",
      "Distribution: world\n",
      "Reply-To: egreen@east.sun.com\n",
      "NNTP-Posting-Host: laser.east.sun.com\n",
      "\n",
      "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
      "> \n",
      "> The question for the day is re: passenger helmets, if you don't know for \n",
      ">certain who's gonna ride with you (like say you meet them at a .... church \n",
      ">meeting, yeah\n"
     ]
    }
   ],
   "source": [
    "print(news_data.data[0][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 설명  \n",
    "- scikit-learn 내장 data  \n",
    "- 영문 20개 topic data로, target 0 ~ 19 총 20개 topic으로 된 정답지가 있음  \n",
    "- 18846 의 data(문단) 이 있으며, 각 문단별 길이는 모두 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 클래스의 값과 분포도 \n",
      " 0     799\n",
      "1     973\n",
      "2     985\n",
      "3     982\n",
      "4     963\n",
      "5     988\n",
      "6     975\n",
      "7     990\n",
      "8     996\n",
      "9     994\n",
      "10    999\n",
      "11    991\n",
      "12    984\n",
      "13    990\n",
      "14    987\n",
      "15    997\n",
      "16    910\n",
      "17    940\n",
      "18    775\n",
      "19    628\n",
      "dtype: int64\n",
      "target 클래스의 이름들 \n",
      " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, (18846,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print('target 클래스의 값과 분포도 \\n', pd.Series(news_data.target).value_counts().sort_index())\n",
    "print('target 클래스의 이름들 \\n',news_data.target_names)\n",
    "len(news_data.target_names), pd.Series(news_data.target).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 & 테스트용 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# subset='train'으로 학습용(Train) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
    "# body 만 활용하기 위해 제거함\n",
    "train_news= fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
    "X_train = train_news.data\n",
    "y_train = train_news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "11314\n",
      "11314\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "What I did NOT get with my drive (CD300i) is the System Install CD you\n",
      "listed as #1.  Any ideas about how I can get one?  I bought my IIvx 8/120\n",
      "from Direct Express in Chicago (no complaints at all -- good price & good\n",
      "service).\n",
      "\n",
      "BTW, I've heard that the System Install CD can be used to boot the mac;\n",
      "however, my drive will NOT accept a CD caddy is the machine is off.  How can\n",
      "you boot with it then?\n",
      "\n",
      "--Dave\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_news.data[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 크기 11314 , 테스트 데이터 크기 7532\n"
     ]
    }
   ],
   "source": [
    "# subset='test'으로 테스트(Test) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
    "test_news= fetch_20newsgroups(subset='test',remove=('headers', 'footers','quotes'),random_state=156)\n",
    "X_test = test_news.data\n",
    "y_test = test_news.target\n",
    "print('학습 데이터 크기 {0} , 테스트 데이터 크기 {1}'.format(len(train_news.data) , len(test_news.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count 피처 벡터화 변환과 머신러닝 모델 학습/예측/평가\n",
    "* 주의: 학습 데이터에 대해 fit( )된 CountVectorizer를 이용해서 테스트 데이터를 피처 벡터화 해야함.   \n",
    "* 테스트 데이터에서 다시 CountVectorizer의 fit_transform()을 수행하거나 fit()을 수행 하면 안됨.   \n",
    "* 이는 이렇게 테스트 데이터에서 fit()을 수행하게 되면 기존 학습된 모델에서 가지는 feature의 갯수가 달라지기 때문임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.feature_extraction.text.CountVectorizer  \n",
    "[__CountVectorizer 설명__](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)  \n",
    "- parameter 간단요약  \n",
    "> stop_words : 불용어 사전을 거치게 하는 것. english 중심이다.  \n",
    "> tokenizer : 내가 만든 tokenizer 객체를 불러올 수 있다. default = None  \n",
    "> ngram_range : n-gram 사용시 활용한다.  \n",
    "> max_df : ex> max_df=100 일 경우, 특정 단어가 100 번 이상 (전체어휘사전기준) 등장하면, 그 단어는 수식어,관용어(a,an,the) 일 수 있으니, 강제로 특정 값이상이면 어휘사전 구성시 제외  \n",
    "> min_df : 상기 max_df 컨셉의 반대  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 & 테스트 데이터 Text의 CountVectorizer Shape: (11314, 101631) (7532, 101631)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Count Vectorization으로 feature extraction 변환 수행. \n",
    "cnt_vect = CountVectorizer() ## max_df=100 . 100개 이상이 되는 단어는 무시한다... min_df : 반대의 의미\n",
    "cnt_vect.fit(X_train)\n",
    "X_train_cnt_vect = cnt_vect.transform(X_train) ## vector화 명령어\n",
    "\n",
    "# 학습 데이터로 fit( )된 CountVectorizer를 이용하여 테스트 데이터를 feature extraction 변환 수행. \n",
    "X_test_cnt_vect = cnt_vect.transform(X_test) ## X_train 으로 완성한 어휘사전 기준으로 vectorize\n",
    "\n",
    "print('학습 & 테스트 데이터 Text의 CountVectorizer Shape:',X_train_cnt_vect.shape, X_test_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(11314, 101631)\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_cnt_vect))\n",
    "print(X_train_cnt_vect.todense().shape) ## csr_matrix 를 numpy matrix로 변환해준 이후, shape 확인\n",
    "print(len(X_train_cnt_vect.todense()[0])) ## 메모리용량때문에 모두는 표현 불가\n",
    "print(len(X_train_cnt_vect.todense()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 CSR_MATRIX 구조로 return한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 101631)\n",
      "(1, 101631)\n",
      "(1, 101631)\n",
      "(1, 101631)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cnt_vect[0].todense().shape) ## toarray() 도 가능\n",
    "print(X_train_cnt_vect[1].todense().shape)\n",
    "print(X_train_cnt_vect[21].todense().shape)\n",
    "print(X_train_cnt_vect[0].toarray().shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 문단 크기는 columns : 101631 로 고정된것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.CountVectorizer'> <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(cnt_vect), type(X_train_cnt_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what', 96391), ('did', 33551), ('not', 66511), ('get', 43217), ('with', 96917)]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in cnt_vect.vocabulary_.items()][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 101631)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cnt_vect[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(11314, 101631)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 2223)\t1\n",
      "  (0, 16251)\t1\n",
      "  (0, 16406)\t1\n",
      "  (0, 17936)\t1\n",
      "  (0, 18903)\t1\n",
      "  (0, 19756)\t1\n",
      "  (0, 20123)\t1\n",
      "  (0, 21987)\t1\n",
      "  (0, 23663)\t2\n",
      "  (0, 23790)\t1\n",
      "  (0, 24444)\t1\n",
      "  (0, 25370)\t1\n",
      "  (0, 25590)\t3\n",
      "  (0, 26271)\t3\n",
      "  (0, 26277)\t1\n",
      "  (0, 26992)\t1\n",
      "  (0, 28805)\t1\n",
      "  (0, 31939)\t1\n",
      "  (0, 33551)\t1\n",
      "  (0, 33799)\t1\n",
      "  (0, 35147)\t2\n",
      "  (0, 38824)\t1\n",
      "  (0, 41715)\t1\n",
      "  (0, 43217)\t2\n",
      "  (0, 43961)\t2\n",
      "  :\t:\n",
      "  (0, 49447)\t1\n",
      "  (0, 50300)\t2\n",
      "  (0, 51136)\t3\n",
      "  (0, 51326)\t1\n",
      "  (0, 56936)\t1\n",
      "  (0, 58921)\t1\n",
      "  (0, 58962)\t1\n",
      "  (0, 64435)\t3\n",
      "  (0, 66242)\t1\n",
      "  (0, 66511)\t2\n",
      "  (0, 67683)\t1\n",
      "  (0, 68102)\t1\n",
      "  (0, 73151)\t1\n",
      "  (0, 81774)\t1\n",
      "  (0, 87099)\t2\n",
      "  (0, 88519)\t1\n",
      "  (0, 88532)\t4\n",
      "  (0, 88587)\t1\n",
      "  (0, 89360)\t1\n",
      "  (0, 92875)\t1\n",
      "  (0, 93870)\t1\n",
      "  (0, 96391)\t1\n",
      "  (0, 96683)\t1\n",
      "  (0, 96917)\t2\n",
      "  (0, 100208)\t2\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cnt_vect.ndim)\n",
    "print(X_train_cnt_vect.shape)\n",
    "print(type(X_train_cnt_vect[0]))\n",
    "print(X_train_cnt_vect[0]) ## tuple 로 구성된 csr_matrix 를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 101631)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cnt_vect[0:10].shape) ## 여전히 2차원임  \n",
    "print(X_train_cnt_vect[0].ndim) ## 여전히 2차원임  \n",
    "## X_train_cnt_vect 은 csr_matrix 구조로, array slice와는 다르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['120', 'about', 'accept', 'all', 'any', 'as', 'at', 'be', 'boot',\n",
       "       'bought', 'btw', 'caddy', 'can', 'cd', 'cd300i', 'chicago',\n",
       "       'complaints', 'dave', 'did', 'direct', 'drive', 'express', 'from',\n",
       "       'get', 'good', 'heard', 'how', 'however', 'ideas', 'iivx', 'in',\n",
       "       'install', 'is', 'it', 'listed', 'mac', 'machine', 'my', 'no',\n",
       "       'not', 'off', 'one', 'price', 'service', 'system', 'that', 'the',\n",
       "       'then', 'to', 'used', 've', 'what', 'will', 'with', 'you'],\n",
       "      dtype='<U81')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(cnt_vect.inverse_transform(X_train_cnt_vect[0])))\n",
    "cnt_vect.inverse_transform(X_train_cnt_vect[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "**Test numpy array slice 와 비교**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1, 0, 2],[0, 0, 3],[4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[0].ndim)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4, 15, 10,  2,  0,  0,  6, 18, 13, 17])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorized Logistic Regression 의 예측 정확도는 0.617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# LogisticRegression을 이용하여 학습/예측/평가 수행. \n",
    "lr_clf = LogisticRegression(solver='liblinear')  # default:lbfgs\n",
    "lr_clf.fit(X_train_cnt_vect , y_train)\n",
    "pred = lr_clf.predict(X_test_cnt_vect)\n",
    "print('CountVectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 피처 변환과 머신러닝 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 & 테스트 데이터 Text의 TfidfVectorizer Shape: (11314, 101631) (7532, 101631)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환. \n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "print('학습 & 테스트 데이터 Text의 TfidfVectorizer Shape:',X_train_tfidf_vect.shape, X_test_tfidf_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x101631 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 55 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf_vect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression 의 예측 정확도는 0.678\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression을 이용하여 학습/예측/평가 수행. \n",
    "lr_clf = LogisticRegression(solver='liblinear')  # default:lbfgs\n",
    "lr_clf.fit(X_train_tfidf_vect , y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stop words 필터링을 추가하고 ngram을 기본(1,1)에서 (1,2)로 변경하여 피처 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.690\n"
     ]
    }
   ],
   "source": [
    "# stop words 필터링을 추가하고 ngram을 기본(1,1)에서 (1,2)로 변경하여 Feature Vectorization 적용.\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300 )\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression(solver='liblinear')  # default:lbfgs\n",
    "lr_clf.fit(X_train_tfidf_vect , y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV로 LogisticRegression C 하이퍼 파라미터 튜닝\n",
    "* C(float, default=1.0) : Inverse of regularization strength(alpha); C=1/alpha, must be a positive float. Like in support vector machines, smaller values specify stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression best C parameter : {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 최적 C 값 도출 튜닝 수행. CV는 3 Fold셋으로 설정. \n",
    "params = { 'C':[0.01, 0.1, 1, 5, 10]}\n",
    "grid_cv_lr = GridSearchCV( lr_clf , param_grid= params, cv=3 , scoring='accuracy' , verbose=0 )\n",
    "grid_cv_lr.fit(X_train_tfidf_vect , y_train)\n",
    "print('Logistic Regression best C parameter :',grid_cv_lr.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.704\n"
     ]
    }
   ],
   "source": [
    "# 최적 C 값으로 학습된 grid_cv로 예측 수행하고 정확도 평가. \n",
    "pred = grid_cv_lr.predict( X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 사이킷런 파이프라인(Pipeline) 사용 및 GridSearchCV와의 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline을 통한 Logistic Regression 의 예측 정확도는 0.704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# TfidfVectorizer 객체를 tfidf_vect 객체명으로, LogisticRegression객체를 lr_clf 객체명으로 생성하는 Pipeline생성\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)),\n",
    "    ('lr_clf', LogisticRegression(solver='liblinear', C=10))\n",
    "])\n",
    "\n",
    "# 별도의 TfidfVectorizer객체의 fit_transform( )과 LogisticRegression의 fit(), predict( )가 필요 없음. \n",
    "# pipeline의 fit( ) 과 predict( ) 만으로 한꺼번에 Feature Vectorization과 ML 학습/예측이 가능. \n",
    "pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_test)\n",
    "print('Pipeline을 통한 Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7532 [ 3 11  1  7  8  1 16  6  4 18]\n"
     ]
    }
   ],
   "source": [
    "print(len(pred), pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed: 18.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7550828826229531 {'lr_clf__C': 10, 'tfidf_vect__max_df': 700, 'tfidf_vect__ngram_range': (1, 2)}\n",
      "Pipeline을 통한 Logistic Regression 의 예측 정확도는 0.702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
    "    ('lr_clf', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "# Pipeline에 기술된 각각의 객체 변수에 언더바(_)2개를 연달아 붙여 GridSearchCV에 사용될 \n",
    "# 파라미터/하이퍼 파라미터 이름과 값을 설정. . \n",
    "params = { 'tfidf_vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "           'tfidf_vect__max_df': [100, 300, 700],\n",
    "           'lr_clf__C': [1,5,10]\n",
    "}\n",
    "\n",
    "# GridSearchCV의 생성자에 Estimator가 아닌 Pipeline 객체 입력\n",
    "grid_cv_pipe = GridSearchCV( pipeline,param_grid =params, cv=3 , scoring='accuracy',verbose=1)\n",
    "grid_cv_pipe.fit(X_train , y_train)\n",
    "print(grid_cv_pipe.best_score_ , grid_cv_pipe.best_params_)\n",
    "\n",
    "pred = grid_cv_pipe.predict(X_test)\n",
    "print('Pipeline을 통한 Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSR-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ind = np.array([0, 1, 2])\n",
    "col_ind = np.array([1, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = np.ones(3)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sparse = sparse.csr_matrix((k, (row_ind, col_ind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (2, 1)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_ind[0],col_ind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_ind[1],col_ind[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_ind[2],col_ind[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
