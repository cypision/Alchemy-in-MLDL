{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_embedding_add_oob_Word.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOq5k1mJJwT/y6LWubnTX0d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cypision/Alchemy-in-MLDL/blob/master/word_embedding_add_oob_Word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se9q_u32hdxl"
      },
      "source": [
        "__웰니스_대화_스크립트_데이터셋 Embedding 하기__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr_02czTKxfP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VFfDWEoxdBd",
        "outputId": "d7dffac7-2320-4f12-f8a7-c7bc76603d5d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v6CI95Nxyd3",
        "outputId": "d8215d4d-2d9e-4f3d-b91b-6abc725429d4"
      },
      "source": [
        "!pip install konlpy\n",
        "!pip install jpype1==0.7.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/9e2c0dbf9df856e6392a1aec1d18006c60b175aa4e31d351e8278a8a63c0/JPype1-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 59.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.9MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, beautifulsoup4, tweepy, colorama, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.2.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n",
            "Collecting jpype1==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/09/e19ce27d41d4f66d73ac5b6c6a188c51b506f56c7bfbe6c1491db2d15995/JPype1-0.7.0-cp36-cp36m-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 12.2MB/s \n",
            "\u001b[?25hInstalling collected packages: jpype1\n",
            "  Found existing installation: JPype1 1.2.0\n",
            "    Uninstalling JPype1-1.2.0:\n",
            "      Successfully uninstalled JPype1-1.2.0\n",
            "Successfully installed jpype1-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqRr-qVXx_lV"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import random\n",
        "import pandas as pd\n",
        "random.seed(1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXHIir5pyLpw"
      },
      "source": [
        "EXCEL_FILE_NALE = \"/content/웰니스_대화_스크립트_데이터셋.xlsx\"\n",
        "data = pd.read_excel(EXCEL_FILE_NALE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3hM32EBySSm"
      },
      "source": [
        "DATA = []\n",
        "RESPONSE = {}\n",
        " \n",
        "for i in range(len(data[\"구분\"])):\n",
        "  label = data[\"구분\"][i]\n",
        "  label_split = label.split(\"/\")\n",
        "  label_1 = \"/\".join(label_split[:2])\n",
        "  sent = data[\"유저\"][i]\n",
        "  if label_1 != \"모호함\":\n",
        "    DATA.append([\"Sent_{}\".format(i), sent, label_1, label])\n",
        "    if label_1 in RESPONSE:  \n",
        "      if not pd.isnull(data[\"챗봇\"][i]): \n",
        "        RESPONSE[label_1].append(data[\"챗봇\"][i])\n",
        "    else: \n",
        "      if not pd.isnull(data[\"챗봇\"][i]):  \n",
        "        RESPONSE[label_1] = [data[\"챗봇\"][i]]\n",
        " \n",
        "\"\"\"random shuffle & make them into train/test set\"\"\"\n",
        "labels = [dat[2] for dat in DATA]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ac76lfyybyF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(DATA, random_state = 2020, stratify = labels, test_size = 400)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4czqvCIykB2",
        "outputId": "270f1871-35dc-481d-f712-ef5c9f7b09e7"
      },
      "source": [
        "print(\"Data Example\")\n",
        "for i in range(5):\n",
        "  print(train[i])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Example\n",
            "['Sent_4393', '뭔가 하루종일 이렇게 들뜬 기분이다 보니까 잠도 잘 안 와.', '증상/불면', '증상/불면']\n",
            "['Sent_603', '아무한테나 화내고 그러지는 않아.', '감정/분노', '감정/분노']\n",
            "['Sent_4224', '잠자리에 누워도 맨날 뒤척이고... 잠을 제대로 잘 수 있을 리가 없지.', '증상/불면', '증상/불면']\n",
            "['Sent_3849', '5일 전에는 새벽에 일어나서 화장실을 가다가 순간적으로 정신을 잃었어.', '증상/기절', '증상/기절']\n",
            "['Sent_666', '그냥 감정이입이 심하게 되고 불안감도 잘 느끼는 것 같아요.', '감정/불안감', '감정/불안감']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjcEyicUyuhb"
      },
      "source": [
        "**기존 embedding layer와의 관계파악**  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEVc3huVyrRV"
      },
      "source": [
        "from konlpy.tag import Komoran, Hannanum, Kkma, Okt ## using only Komoran object\n",
        "\n",
        "## 형태소분석 함수 만들기\n",
        "komoran = Komoran()\n",
        "def tokenize(word):\n",
        "  return komoran.morphs(word)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNx99p75zda6"
      },
      "source": [
        "**기존 Ebedding layer가져오기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxEiLKCozEpO",
        "outputId": "a6068190-45e5-41fe-c5df-28b3946ce200"
      },
      "source": [
        "import numpy as np\n",
        "with open(\"/content/gdrive/My Drive/CNS_NLP/vecs.tsv\") as f:\n",
        "  vecs = [v.strip() for v in f.readlines()]\n",
        "final_embeddings = [v.split(\"\\t\") for v in vecs]\n",
        "final_embeddings = np.array(final_embeddings, dtype=\"float32\")\n",
        "with open(\"/content/gdrive/My Drive/CNS_NLP/meta.tsv\") as f:\n",
        "  vocab_list = [v.strip() for v in f.readlines()]\n",
        "\n",
        "\n",
        "print(final_embeddings.shape)\n",
        "print(len(vocab_list))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70002, 128)\n",
            "70002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIEJFThqzrbP"
      },
      "source": [
        "**신규 sentece들을 tokenize 했을때, 기존 meta token들과의 관계 파악하기**  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAoyW90mzYjx"
      },
      "source": [
        "import collections\n",
        "tot_tokens = 0\n",
        "oov_counter = collections.Counter()\n",
        "Tokenized_train = []"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2RMkCq1zY1l"
      },
      "source": [
        "for data_lst in train:\n",
        "  sentence = data_lst[1]\n",
        "  tokenized_sent = tokenize(sentence)\n",
        "  tot_tokens += len(tokenized_sent) ## 전체 tocken 수 count 중복허용\n",
        "\n",
        "  for word in tokenized_sent:\n",
        "    if word not in vocab_list:\n",
        "      oov_counter[word] += 1\n",
        "  Tokenized_train.append([data_lst[0], tokenized_sent, data_lst[2]])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkBLhZcnzZA5",
        "outputId": "03c7e934-f22f-4c89-a2fc-9e75276f21a2"
      },
      "source": [
        "print(\"# OOV Tokens:\", len(oov_counter))\n",
        "# print(\"{}/{} ({:.2f}%) are [UNK] in train tokens\".format(sum(oov_counter.values()) , tot_tokens , 100*sum(oov_counter.values())/tot_tokens))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# OOV Tokens: 471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr6zeLVozZjq"
      },
      "source": [
        "새로 등장한 토큰은 471 개이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4USj9Bk0pOF",
        "outputId": "e46e1a44-7878-4c7e-c1a9-820df5a1b0ac"
      },
      "source": [
        "### 새로 나온 데이터 살펴보기\n",
        "most_common = oov_counter.most_common(len(oov_counter))\n",
        "print(most_common[:10])\n",
        "print(most_common[-10:])\n",
        " \n",
        "### Train 데이터에서 새로 발견한 토큰을 기존 단어 사전에 추가\n",
        "new_vocab_list = vocab_list.copy()\n",
        "new_vocab_list.extend([v[0] for v in most_common])\n",
        "print(\"\\n# New Vocabs = {}\".format(len(new_vocab_list)))\n",
        " \n",
        "##TEMP 신규로 추가한 단어 사전\n",
        "print(new_vocab_list[-30:])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('걔', 37), ('더라구', 20), ('어떡하지', 17), ('여치', 13), ('대요', 13), ('두근거리', 13), ('뒤척이', 12), ('갑갑', 12), ('아파서', 10), ('얼른', 8)]\n",
            "[('버럭', 1), ('아차', 1), ('싱숭생숭하네요…', 1), ('대견', 1), ('돌덩이', 1), ('쭈꾸미를', 1), ('혹시나', 1), ('헷갈려요.', 1), ('근육통', 1), ('볼링공', 1)]\n",
            "\n",
            "# New Vocabs = 70473\n",
            "['과태료', '피시방', '얼결', '울렁거려요.', '부들부들', '흥청망청', '둥둥', '째려보', '까마득', '흔들다리', '갓길', '틈틈히', '뒷머리', '뒷목', '짓누르', '예뻐서', '스르륵', '꿈쩍', '홀딱', '문제집', '버럭', '아차', '싱숭생숭하네요…', '대견', '돌덩이', '쭈꾸미를', '혹시나', '헷갈려요.', '근육통', '볼링공']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv-DmfH31GR0",
        "outputId": "98d2bfd1-eecd-4ea1-8bf4-79c38d38705a"
      },
      "source": [
        "print(len(new_vocab_list)) ## 기존 70002 -> 70473 으로 늘어났다."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4USD1kbO1eq8",
        "outputId": "70210081-652c-479a-d892-e33394da38d0"
      },
      "source": [
        "## show sample data and compare before vs after\n",
        "print(len(Tokenized_train),len(train))\n",
        "print(train[0],\"\\n=============================================================================================================\\n\",Tokenized_train[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4651 4651\n",
            "['Sent_4393', '뭔가 하루종일 이렇게 들뜬 기분이다 보니까 잠도 잘 안 와.', '증상/불면', '증상/불면'] \n",
            "=============================================================================================================\n",
            " ['Sent_4393', ['뭐', 'ㄴ가', '하루', '종일', '이렇', '게', '들뜨', 'ㄴ', '기분', '이', '다', '보', '니까', '잠도', '잘', '안', '오', '아', '.'], '증상/불면']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d1R5-S01wLb"
      },
      "source": [
        "**train,test 에 있는 데이터들을 embedding 하기**  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySBJ0GAb4tr4"
      },
      "source": [
        "from utils import TextEncoder\n",
        "text_encoder = TextEncoder(new_vocab_list) ## new_vocab_list 기준으로 dictionary를 만듬."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCAREIFa8O49"
      },
      "source": [
        "__TextEncoder__  \n",
        "- TextEncoder 이전에 만든 객체임  \n",
        "- new_vocab_list 기준으로 만들었으며, token_to_id , id_to_tocken 기능을 수행한다  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFf8AQ5W3zxE"
      },
      "source": [
        "# train_ids, train_labels, label_map = create_cls_feature(Tokenized_train, text_encoder, max_seq_len=MAX_LEN, )\n",
        "label_map=None\n",
        "# examples=Tokenized_train\n",
        "text_encoder=text_encoder\n",
        "max_seq_len=None"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_-4JU6v3eD1"
      },
      "source": [
        "input_ids = [] # 정수 인덱스로 변환한 문장들의 리스트\n",
        "labels = [] # 정답 라벨 리스트\n",
        "MAX_LEN = 50 # sequence 길이"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v42g4y_Z3KDC"
      },
      "source": [
        "# if label_map is None: #label_map이 없으면 -> 이번에 데이터를 처리하면서 새로 생성함\n",
        "#     CREATE_LABEL_MAP = True\n",
        "#     label_map = {}\n",
        "#     label_index = 0\n",
        "# else: \n",
        "#     CREATE_LABEL_MAP = False\n",
        "#     print(\"** Start creating features using label map\")\n",
        "#     print(label_map)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI37LNqM7zzi"
      },
      "source": [
        "**실제 처리 과정**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3uY3aT4_fTt"
      },
      "source": [
        "# CREATE_LABEL_MAP = True ?\n",
        "label_map = {}\n",
        "label_index = 0"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMIptBc-3s0z"
      },
      "source": [
        "for example in Tokenized_train:\n",
        "    idx, tokenized_sent, label = example\n",
        "\n",
        "    ## 1. text_encoder 사용해 정수로 변환 \n",
        "    input_id = text_encoder.convert_tokens_to_ids(tokenized_sent)\n",
        "    if len(input_id) == 0: ## list로 return 받은 정수 인덱스들의 길이가 0 이며. 즉 없으면.\n",
        "        print(\"Sentence with length = 0... continue\", example)\n",
        "        continue\n",
        "\n",
        "    ## 2. label 매핑 & index로 변환\n",
        "    if label in label_map: ## label이 label_map에 key로 등록되어 있으면 = label이 신규가 아니면\n",
        "        label_id = label_map[label]\n",
        "    else:\n",
        "      # label map에 추가\n",
        "      label_map[label] = label_index\n",
        "      label_index += 1\n",
        "      label_id = label_map[label]        \n",
        "\n",
        "    ## 전체 리스트에 append\n",
        "    input_ids.append(input_id)\n",
        "    labels.append(label_id)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCj5RW0878EK",
        "outputId": "978370c0-0b23-459a-d552-9a7ccf8c7040"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\"\"\" max_seq_len을 넘는 문장은 절단, 모자르는 것은 PADDING \"\"\"\n",
        "input_ids = pad_sequences(input_ids,maxlen=MAX_LEN,padding=\"post\",truncating=\"pre\")\n",
        "\n",
        "## np.array로 변환해 리턴\n",
        "input_ids = np.array(input_ids)\n",
        "labels = np.array(labels)\n",
        "\n",
        "assert len(input_ids) == len(labels)\n",
        "print(\"** {} examples processed\".format(len(input_ids)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** 4651 examples processed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2pA_Lfq78Py",
        "outputId": "f980b1fc-f671-47be-8673-6d117da97b99"
      },
      "source": [
        "print(len(input_ids[0]))\n",
        "input_ids[0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4031,  1476,  1453, 13158,   497,    40, 14785,     9,  5861,\n",
              "           3,     8,    85,  4852, 29044,   359,   163,   101,    18,\n",
              "           4,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC51AERhBtY5"
      },
      "source": [
        "for i in range(len(input_ids)):\n",
        "  if len(input_ids[i]) > 50: ## max_sequence = 50 을 넘는 값이 있는지 확인. 당연히 없다.\n",
        "    print(input_ids[i])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuZq0Q9U78ZL",
        "outputId": "115800c7-b554-4e7c-e2b3-542bfcbe1bdc"
      },
      "source": [
        "print(len(Tokenized_train))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NrjoILOkQVQ",
        "outputId": "59628a6b-a7f0-459a-c897-be5b0f658fab"
      },
      "source": [
        "train_ids = input_ids.copy(); train_labels = labels.copy()\n",
        "\n",
        "label_map_reverse = {}\n",
        "for key,val in label_map.items():\n",
        "  label_map_reverse[val] = key\n",
        "\n",
        "print(train_ids[0])\n",
        "print(train_labels[0])\n",
        "print(len(label_map)) ## dict type이므로 key값을 넣어야 한다.\n",
        "print(label_map_reverse[train_labels[0]]) ## dict type이므로 key값을 넣어야 한다."
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 4031  1476  1453 13158   497    40 14785     9  5861     3     8    85\n",
            "  4852 29044   359   163   101    18     4     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0]\n",
            "0\n",
            "176\n",
            "증상/불면\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPYmqAB378jM"
      },
      "source": [
        "input_ids 은 Tokenized_train 값들이 문장길이 Maxlen = 50 사이즈로, index화 된 값이다.  \n",
        "input 값들이 Embedding 계층을 통과하면, Embedding 된 벡터(단어)들로 학습되기 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgwgan-p784h",
        "outputId": "ab8f2cd3-71c8-498b-9e9c-284850c535ee"
      },
      "source": [
        "label_map.keys()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['증상/불면', '감정/분노', '증상/기절', '감정/불안감', '증상/두근거림', '배경/건강문제', '배경/취업', '감정/우울감', '배경/대인관계', '배경/어린시절', '감정/자살충동', '감정/외로움', '증상/자살시도', '감정/걱정', '배경/학업', '증상/무기력', '증상/식욕저하', '일반대화', '배경/결혼', '상태/증상지속', '배경/학교', '감정/짜증', '배경/부모', '증상/두통', '증상/피해망상', '감정/자존감저하', '배경/성격', '증상/기억상실', '배경/사업', '감정/감정조절이상', '배경/전연인', '감정/불편감', '배경/경제적문제', '치료이력/병원내원', '배경/친구', '배경/가족', '배경/여자친구', '치료이력/검사', '증상/어지러움', '감정/부정적사고', '감정/눈물', '배경/시댁', '증상/반복행동', '감정/좌절', '배경/자녀', '감정/무력감', '배경/사고', '배경/직장', '증상/기억력저하', '증상/은둔', '증상/환청', '증상/이명', '부가설명', '감정/심란', '감정/답답', '감정/힘듦', '감정/공허감', '배경/남편', '증상/반복사고', '감정/무서움', '감정/두려움', '증상/피로', '감정/속상함', '감정/통제력상실', '배경/생활', '배경/종교', '감정/자괴감', '증상/환각', '배경/음주', '배경/대학', '자가치료/심리조절', '감정/당황', '감정/즐거움', '배경/남자친구', '증상/생리불순', '감정/불쾌감', '증상/공황발작', '감정/억울함', '감정/배신감', '증상/호흡곤란', '감정/신경쓰임', '배경/문제', '배경/귀국', '배경/애완동물', '배경/타인', '감정/절망감', '증상/이인감', '증상/대화기피', '감정/서운함', '내원이유/치료', '감정/괴로움', '치료이력/응급실', '감정/자신감저하', '감정/화', '감정/충격', '증상/집중력저하', '증상/자해', '배경/이사', '배경/연애', '감정/살인욕구', '감정/불신', '감정/기분저하', '감정/의욕상실', '배경/군대', '감정/공포', '증상/과대망상', '배경/자각', '상태/양호', '증상/폭식', '감정/예민함', '감정/모호함', '증상/과수면', '증상/대인기피', '증상/힘빠짐', '배경/임신', '증상/체중감소', '배경/이혼', '감정/긴장', '증상/죽음공포', '감정/의기소침', '현재상태/증상지속', '증상/체력저하', '증상/통증', '증상/악몽', '증상/공격적성향', '증상/컨디션저조', '증상/성욕상승', '감정/고독감', '증상/가슴통증', '배경/육아', '감정/후회', '배경/아르바이트', '내원이유/상담', '배경/공부', '현재상태/증상악화', '증상/시력저하', '증상/신체이상', '증상/건강염려', '감정/무미건조', '감정/불만', '감정/미움', '증상/알코올의존', '증상/기절예기', '감정/슬픔', '감정/생각', '증상/만성피로', '현재상태/증상감소', '감정/과민반응', '증상/가슴떨림', '감정/기시감', '감정/미안함', '감정/허무함', '증상/체중증가', '감정/멍함', '감정/죄책감', '증상/메스꺼움', '감정/비관적', '자가치료/운동', '자가치료/충분한휴식', '증상/발작', '증상/인지기능저하', '내원이유/의사소견', '증상/저림현상', '증상/가슴답답', '증상/성격변화', '증상/소화불량', '증상/편두통', '증상/떨림', '배경/유학', '상태/증상감소', '감정/창피함', '증상/속쓰림', '감정/곤혹감', '원인/없음', '감정/초조함', '배경/진로'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOvEdsoy78-c",
        "outputId": "6f288e99-5e00-4344-bc31-7af8a7bf1e1f"
      },
      "source": [
        "print(train_ids.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4651, 50)\n",
            "(4651,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35DqGMXmja3R"
      },
      "source": [
        "__Test 데이터에 대해, 토크나이즈 하고, Embedding 하기__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQl2g2EF79LZ"
      },
      "source": [
        "## 토크나이즈\n",
        "Tokenized_test = []\n",
        "\n",
        "for data_lst in test:\n",
        "  sentence = data_lst[1]\n",
        "  tokenized_sent = tokenize(sentence)\n",
        "  \n",
        "  for word in tokenized_sent:\n",
        "    if word not in vocab_list:\n",
        "      oov_counter[word] += 1\n",
        "  Tokenized_test.append([data_lst[0], tokenized_sent, data_lst[2]])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRWU3CPA79PC",
        "outputId": "9760fce5-92b4-42f6-cb95-616226ff318d"
      },
      "source": [
        "print(len(test),len(Tokenized_test))\n",
        "Tokenized_test[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400 400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sent_1296', ['저', '는', '이제', '망하', '았', '어요', '…'], '감정/좌절']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl4BdFyyjoU8",
        "outputId": "6e517597-52db-4c33-8b4c-dd18a5ade58a"
      },
      "source": [
        "from utils import TextEncoder,create_cls_feature\n",
        "\n",
        "test_ids, test_labels, _ = create_cls_feature(Tokenized_test, text_encoder, max_seq_len=50, label_map = label_map)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** Start creating features using label map\n",
            "{'증상/불면': 0, '감정/분노': 1, '증상/기절': 2, '감정/불안감': 3, '증상/두근거림': 4, '배경/건강문제': 5, '배경/취업': 6, '감정/우울감': 7, '배경/대인관계': 8, '배경/어린시절': 9, '감정/자살충동': 10, '감정/외로움': 11, '증상/자살시도': 12, '감정/걱정': 13, '배경/학업': 14, '증상/무기력': 15, '증상/식욕저하': 16, '일반대화': 17, '배경/결혼': 18, '상태/증상지속': 19, '배경/학교': 20, '감정/짜증': 21, '배경/부모': 22, '증상/두통': 23, '증상/피해망상': 24, '감정/자존감저하': 25, '배경/성격': 26, '증상/기억상실': 27, '배경/사업': 28, '감정/감정조절이상': 29, '배경/전연인': 30, '감정/불편감': 31, '배경/경제적문제': 32, '치료이력/병원내원': 33, '배경/친구': 34, '배경/가족': 35, '배경/여자친구': 36, '치료이력/검사': 37, '증상/어지러움': 38, '감정/부정적사고': 39, '감정/눈물': 40, '배경/시댁': 41, '증상/반복행동': 42, '감정/좌절': 43, '배경/자녀': 44, '감정/무력감': 45, '배경/사고': 46, '배경/직장': 47, '증상/기억력저하': 48, '증상/은둔': 49, '증상/환청': 50, '증상/이명': 51, '부가설명': 52, '감정/심란': 53, '감정/답답': 54, '감정/힘듦': 55, '감정/공허감': 56, '배경/남편': 57, '증상/반복사고': 58, '감정/무서움': 59, '감정/두려움': 60, '증상/피로': 61, '감정/속상함': 62, '감정/통제력상실': 63, '배경/생활': 64, '배경/종교': 65, '감정/자괴감': 66, '증상/환각': 67, '배경/음주': 68, '배경/대학': 69, '자가치료/심리조절': 70, '감정/당황': 71, '감정/즐거움': 72, '배경/남자친구': 73, '증상/생리불순': 74, '감정/불쾌감': 75, '증상/공황발작': 76, '감정/억울함': 77, '감정/배신감': 78, '증상/호흡곤란': 79, '감정/신경쓰임': 80, '배경/문제': 81, '배경/귀국': 82, '배경/애완동물': 83, '배경/타인': 84, '감정/절망감': 85, '증상/이인감': 86, '증상/대화기피': 87, '감정/서운함': 88, '내원이유/치료': 89, '감정/괴로움': 90, '치료이력/응급실': 91, '감정/자신감저하': 92, '감정/화': 93, '감정/충격': 94, '증상/집중력저하': 95, '증상/자해': 96, '배경/이사': 97, '배경/연애': 98, '감정/살인욕구': 99, '감정/불신': 100, '감정/기분저하': 101, '감정/의욕상실': 102, '배경/군대': 103, '감정/공포': 104, '증상/과대망상': 105, '배경/자각': 106, '상태/양호': 107, '증상/폭식': 108, '감정/예민함': 109, '감정/모호함': 110, '증상/과수면': 111, '증상/대인기피': 112, '증상/힘빠짐': 113, '배경/임신': 114, '증상/체중감소': 115, '배경/이혼': 116, '감정/긴장': 117, '증상/죽음공포': 118, '감정/의기소침': 119, '현재상태/증상지속': 120, '증상/체력저하': 121, '증상/통증': 122, '증상/악몽': 123, '증상/공격적성향': 124, '증상/컨디션저조': 125, '증상/성욕상승': 126, '감정/고독감': 127, '증상/가슴통증': 128, '배경/육아': 129, '감정/후회': 130, '배경/아르바이트': 131, '내원이유/상담': 132, '배경/공부': 133, '현재상태/증상악화': 134, '증상/시력저하': 135, '증상/신체이상': 136, '증상/건강염려': 137, '감정/무미건조': 138, '감정/불만': 139, '감정/미움': 140, '증상/알코올의존': 141, '증상/기절예기': 142, '감정/슬픔': 143, '감정/생각': 144, '증상/만성피로': 145, '현재상태/증상감소': 146, '감정/과민반응': 147, '증상/가슴떨림': 148, '감정/기시감': 149, '감정/미안함': 150, '감정/허무함': 151, '증상/체중증가': 152, '감정/멍함': 153, '감정/죄책감': 154, '증상/메스꺼움': 155, '감정/비관적': 156, '자가치료/운동': 157, '자가치료/충분한휴식': 158, '증상/발작': 159, '증상/인지기능저하': 160, '내원이유/의사소견': 161, '증상/저림현상': 162, '증상/가슴답답': 163, '증상/성격변화': 164, '증상/소화불량': 165, '증상/편두통': 166, '증상/떨림': 167, '배경/유학': 168, '상태/증상감소': 169, '감정/창피함': 170, '증상/속쓰림': 171, '감정/곤혹감': 172, '원인/없음': 173, '감정/초조함': 174, '배경/진로': 175}\n",
            "** 400 examples processed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z4BmTj1m6SK",
        "outputId": "6127f090-893c-45af-a7f5-9652f5eadf8e"
      },
      "source": [
        "print(len(test_ids),len(test_labels))\n",
        "print(test_ids[0])\n",
        "print(test_labels[0])\n",
        "print(len(label_map)) ## dict type이므로 key값을 넣어야 한다.\n",
        "print(label_map_reverse[test_labels[0]]) ## dict type이므로 key값을 넣어야 한다."
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400 400\n",
            "[  594     6  1549 12031    12  1365  2223     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0]\n",
            "43\n",
            "176\n",
            "감정/좌절\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFKmuESPm_Li",
        "outputId": "28923478-8edd-4653-8402-8e8d9ae3aa60"
      },
      "source": [
        "print(test_ids.shape,test_labels.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400, 50) (400,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mugGutNYnMgq"
      },
      "source": [
        "토근화까지 진행된 데이터들을 저장한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcyO5XhQnTbh"
      },
      "source": [
        "# with open(\"/content/gdrive/My Drive/CNS_NLP/Wellness_data_train_tokenized.json\",\"w\") as f:\n",
        "#   f.write(json.dumps(train_ids))\n",
        "# with open(\"/content/gdrive/My Drive/CNS_NLP/Wellness_data_test_tokenized.json\",\"w\") as f:\n",
        "#   f.write(json.dumps(test_ids))\n",
        "# with open(\"/content/gdrive/My Drive/CNS_NLP/Wellness_data_train_tokenized_label.json\",\"w\") as f:\n",
        "#   f.write(json.dumps(train_labels))\n",
        "# with open(\"/content/gdrive/My Drive/CNS_NLP/Wellness_data_test_tokenized_label.json\",\"w\") as f:\n",
        "#   f.write(json.dumps(test_labels))\n",
        "\n",
        "## label_map\n",
        "with open(\"/content/gdrive/My Drive/CNS_NLP/Wellness_data_label_map.json\",\"w\") as f:\n",
        "  f.write(json.dumps(label_map))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56EZhO5AoOqA"
      },
      "source": [
        "## numpy 배열 저장\n",
        "np.save('/content/gdrive/My Drive/CNS_NLP/Wellness_data_train_tokenized',train_ids)\n",
        "np.save('/content/gdrive/My Drive/CNS_NLP/Wellness_data_test_tokenized',test_ids)\n",
        "np.save('/content/gdrive/My Drive/CNS_NLP/Wellness_data_train_tokenized_label',train_labels)\n",
        "np.save('/content/gdrive/My Drive/CNS_NLP/Wellness_data_test_tokenized_label',test_labels)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-mxoFhypVe1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}